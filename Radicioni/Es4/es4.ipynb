{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Document classification con embedding glove"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Import and constants\n",
    "import math\n",
    "import os\n",
    "import glob\n",
    "import random\n",
    "import nltk\n",
    "import numpy as np\n",
    "import math\n",
    "from gensim.models import KeyedVectors\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "BETA=16\n",
    "GAMMA=4\n",
    "SIMILARITY_TRESHOLD = 0.5\n",
    "\n",
    "lemmatizer = nltk.WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "#Utilities\n",
    "\n",
    "#Carica i documenti fornendo il nome della cartella che contiene le cartelle dei singoli topic\n",
    "#Ogni documento viene taggato con il nome della cartella in cui risiede, questo rappresenta la sua classe\n",
    "def load_datasets(parent_folder_name):\n",
    "    dataset = []\n",
    "    # Get a list of all items in the folder\n",
    "    items = os.listdir(parent_folder_name)\n",
    "    # Filter out folders from the list\n",
    "    folder_list = [item for item in items if os.path.isdir(os.path.join(parent_folder_name, item))]\n",
    "    for folder_name in folder_list:\n",
    "        file_list = glob.glob(os.path.join(os.path.join(parent_folder_name, folder_name), \"*\"))\n",
    "\n",
    "        # Iterate over each file\n",
    "        for file_path in file_list:\n",
    "            with open(file_path, \"r\") as file:\n",
    "                content = file.read()\n",
    "                dataset.append([content, folder_name])\n",
    "    return dataset\n",
    "\n",
    "#Fornisce l'embedding di un termine dato glove, in caso il termine non sia trovato fornisce 0\n",
    "def get_embedding(key, glove):\n",
    "    if key in glove:\n",
    "        return glove.get_vector(key)\n",
    "    else:\n",
    "        return np.zeros(300)  # Return a zero vector if the key is not found\n",
    "\n",
    "#Esegue l'embedding di ogni documento del dataset\n",
    "def embed_dataset(dataset, glove):\n",
    "    #Per ogni tupla (Documento,Classificazione)\n",
    "    for tuple in dataset:\n",
    "        #Embeddo il documento\n",
    "        tuple[0] = embed_document(tuple[0], glove)\n",
    "    return dataset\n",
    "\n",
    "#Calcola embedding del documento come la media degli embedding di tutte le parole tokenizzate\n",
    "def embed_document(document, glove):\n",
    "    # Tokenize the sentence into words\n",
    "    words = nltk.word_tokenize(document.lower())\n",
    "\n",
    "    # Embed each word and calculate the average embedding\n",
    "    embeddings = [get_embedding(word, glove) for word in words]\n",
    "    return np.mean(embeddings, axis=0)\n",
    "#Funzione di filtraggio che fornisce tutti i documenti di un dataset aventi una specifica label\n",
    "def get_dataset_elements_with_label(dataset, label):\n",
    "    elements = []\n",
    "    for elem in dataset:\n",
    "        if (elem[1] == label):\n",
    "            elements.append(elem)\n",
    "    return elements"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Caricamento del dataset e di glove"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "#Caricamento del dataset\n",
    "dataset = load_datasets(\"data-es4/data/20_NGs_400\")\n",
    "#Caricamento di glove\n",
    "glove = KeyedVectors.load_word2vec_format(\"glove.6B/glove.6B.300d.txt\", no_header=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Embedding del dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Cavag\\PycharmProjects\\Natural_Language_Techniques\\venv\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3464: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "C:\\Users\\Cavag\\PycharmProjects\\Natural_Language_Techniques\\venv\\lib\\site-packages\\numpy\\core\\_methods.py:192: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "dataset_embedded = embed_dataset(dataset, glove)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Divisione del dataset in training set e test set\n",
    "\n",
    "Decidiamo di lavorare classe per classe per creare un training set bilanciato"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "random.seed(22)\n",
    "#Calcolo l'elenco di tutte le label presenti nel dataset\n",
    "labels_set = set([t[1] for t in dataset_embedded])\n",
    "#Creo le strutture dati\n",
    "x_train_data = []\n",
    "y_train_data = []\n",
    "x_test_data = []\n",
    "y_test_data = []\n",
    "#Per ogni possibile classe\n",
    "for label in labels_set:\n",
    "    #Estraggo dal dataset gli elementi con quella classe\n",
    "    label_dataset = get_dataset_elements_with_label(dataset_embedded, label)\n",
    "    #Li divido in training set e test set\n",
    "    train_set, test_set = train_test_split(label_dataset, test_size=0.1, random_state=19)\n",
    "    #Li aggiungo alle strutture dati\n",
    "    for elem in train_set:\n",
    "        if(isinstance(elem[0], np.ndarray)):\n",
    "            x_train_data.append(elem[0])\n",
    "            y_train_data.append(elem[1])\n",
    "    for elem in test_set:\n",
    "         if(isinstance(elem[0], np.ndarray)):\n",
    "            x_test_data.append(elem[0])\n",
    "            y_test_data.append(elem[1])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Implementazione metodo Rocchio senza Near Positives"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "#Metodo usato per estrarre dal dataset delle feature tutti gli elementi con una label (Usato per calcolare i Positives examples)\n",
    "#Features e Labels sono array collegati, features[0] sono le features dell'esempio 0 che avrà label label[0]\n",
    "def get_features_with_same_label(features, labels, label):\n",
    "    correct_features = []\n",
    "    for i, elem in enumerate(labels):\n",
    "        if (elem == label):\n",
    "            correct_features.append(features[i])\n",
    "    return correct_features\n",
    "\n",
    "#Metodo usato per estrarre dal dataset delle feature tutti gli elementi non aventi una label (Usato per calcolare i Negatives examples)\n",
    "#Features e Labels sono array collegati, features[0] sono le features dell'esempio 0 che avrà label label[0]\n",
    "def get_features_with_different_label(features, labels, label):\n",
    "    correct_features = []\n",
    "    for i, elem in enumerate(labels):\n",
    "        if (elem != label):\n",
    "            correct_features.append(features[i])\n",
    "    return correct_features\n",
    "\n",
    "#Metodo per il training del modello\n",
    "def train_rocchio(features, labels, beta, gamma):\n",
    "    #Calcolo le labels che andrò a modellare\n",
    "    possible_labels = set(labels)\n",
    "    model = []\n",
    "    #Per ogni classe\n",
    "    for label in possible_labels:\n",
    "        #Calcolo gli esempi positives\n",
    "        positive_examples = get_features_with_same_label(features, labels, label)\n",
    "        #Calcolo gli esempi negatives\n",
    "        negative_examples = get_features_with_different_label(features, labels, label)\n",
    "        #Calcolo le medie\n",
    "        positive_examples = beta * np.mean(positive_examples, axis=0)\n",
    "        negative_examples = gamma * np.mean(negative_examples, axis=0)\n",
    "        #Calcolo il modello per la classe\n",
    "        model.append(((positive_examples - negative_examples), label))\n",
    "    return model\n",
    "\n",
    "#Metodo per predire un elemento dato il modello\n",
    "def predict(elem, model):\n",
    "    best_predict = None\n",
    "    best_similarity = -1\n",
    "    #Per ogni possibile classe\n",
    "    for label in model:\n",
    "        #Calcolo la similarità tra il modello della classe e l'mebedding dell'elemento\n",
    "        similarity = cosine_similarity(elem.reshape(1, -1), label[0].reshape(1, -1))[0]\n",
    "        #Salvo la similarità migliore e la ritorno\n",
    "        if (best_similarity == -1):\n",
    "            best_similarity = similarity\n",
    "            best_predict = label[1]\n",
    "        elif (similarity > best_similarity):\n",
    "            best_similarity = similarity\n",
    "            best_predict = label[1]\n",
    "    return best_predict, best_similarity"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Training e test del modello rocchio"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR, EXPECTED sci.crypt GOT comp.sys.mac.hardware WITH SIM:  [0.96002894]\n",
      "ERROR, EXPECTED sci.crypt GOT comp.windows.x WITH SIM:  [0.97191266]\n",
      "ERROR, EXPECTED sci.med GOT talk.religion.misc WITH SIM:  [0.9497588]\n",
      "ERROR, EXPECTED misc.forsale GOT comp.windows.x WITH SIM:  [0.91607043]\n",
      "ERROR, EXPECTED misc.forsale GOT talk.politics.guns WITH SIM:  [0.97130805]\n",
      "ERROR, EXPECTED comp.sys.ibm.pc.hardware GOT comp.windows.x WITH SIM:  [0.91819115]\n",
      "ERROR, EXPECTED comp.sys.ibm.pc.hardware GOT comp.graphics WITH SIM:  [0.97858118]\n",
      "ERROR, EXPECTED comp.windows.x GOT sci.crypt WITH SIM:  [0.98133192]\n",
      "ERROR, EXPECTED comp.windows.x GOT comp.os.ms-windows.misc WITH SIM:  [0.98372821]\n",
      "ERROR, EXPECTED talk.religion.misc GOT sci.crypt WITH SIM:  [0.97989356]\n",
      "ERROR, EXPECTED comp.os.ms-windows.misc GOT comp.windows.x WITH SIM:  [0.93806999]\n",
      "ERROR, EXPECTED comp.os.ms-windows.misc GOT sci.crypt WITH SIM:  [0.97973088]\n",
      "ERROR, EXPECTED rec.sport.baseball GOT sci.med WITH SIM:  [0.9716577]\n",
      "ERROR, EXPECTED rec.sport.baseball GOT comp.windows.x WITH SIM:  [0.92401436]\n",
      "ERROR, EXPECTED comp.sys.mac.hardware GOT comp.sys.ibm.pc.hardware WITH SIM:  [0.96843114]\n",
      "ERROR, EXPECTED comp.sys.mac.hardware GOT comp.sys.ibm.pc.hardware WITH SIM:  [0.96089503]\n",
      "ERROR, EXPECTED rec.sport.hockey GOT rec.sport.baseball WITH SIM:  [0.9009234]\n",
      "ERROR, EXPECTED rec.sport.hockey GOT soc.religion.christian WITH SIM:  [0.97183792]\n",
      "ERROR, EXPECTED sci.electronics GOT comp.windows.x WITH SIM:  [0.95299052]\n",
      "ERROR, EXPECTED talk.politics.guns GOT talk.politics.mideast WITH SIM:  [0.97036089]\n",
      "ERROR, EXPECTED soc.religion.christian GOT talk.politics.misc WITH SIM:  [0.9747526]\n",
      "Accuracy: 46.15384615384615 % N_tests: 39 Hits: 18\n"
     ]
    }
   ],
   "source": [
    "#Alleno il modello\n",
    "model = train_rocchio(x_train_data, y_train_data, BETA, GAMMA)\n",
    "hit = 0\n",
    "#Per ogni modello del test set verifico le predizioni\n",
    "for i, elem in enumerate(x_test_data):\n",
    "    predicted_value, sim = predict(elem, model)\n",
    "    if (predicted_value == y_test_data[i]):\n",
    "        hit += 1\n",
    "    else:\n",
    "        print(\"ERROR, EXPECTED\", y_test_data[i], \"GOT\", predicted_value, \"WITH SIM: \", sim)\n",
    "#Calcolo accuratezza\n",
    "if(hit==0):\n",
    "    prec=0\n",
    "else:\n",
    "    perc=(hit / len(x_test_data))*100\n",
    "print(\"Accuracy:\", perc, \"%\", \"N_tests:\",len(x_test_data),\"Hits:\",hit)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Modello rocchio con near positives\n",
    "Si è proposto di calcolare i near positives come gli elementi che hanno label diversa e una distanza media dagli esempi posivi minore di SIMILARITY_TRESHOLD"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "#Calcola la similarità media tra un esempio negativo e una lista di esempi positivi\n",
    "def calc_avg_similarity(positives, feature):\n",
    "    sims = []\n",
    "    for elem in positives:\n",
    "        sims.append(cosine_similarity(elem.reshape(1, -1), feature.reshape(1, -1))[0])\n",
    "    return np.mean(sims)\n",
    "\n",
    "#Calcola l'elenco dei near positives dato una label corretta\n",
    "def get_features_with_nears_positives(features, positives, labels, label):\n",
    "    correct_features = []\n",
    "    for i, elem in enumerate(labels):\n",
    "        if (elem != label):\n",
    "            sim = calc_avg_similarity(positives,features[i])\n",
    "            if (sim >= SIMILARITY_TRESHOLD):\n",
    "                correct_features.append(features[i])\n",
    "    return correct_features\n",
    "\n",
    "#Allena il modello sfruttando i near positives\n",
    "def train_rocchio_with_near_positives(features, labels, beta, gamma):\n",
    "    possible_labels = set(labels)\n",
    "    model = []\n",
    "    #Per ogni classe\n",
    "    for label in possible_labels:\n",
    "        #Calcolo gli esempi positives\n",
    "        positive_examples = get_features_with_same_label(features, labels, label)\n",
    "        #Calcolo i near positives\n",
    "        near_positives_examples = get_features_with_nears_positives(features, positive_examples, labels, label)\n",
    "        #Faccio le medie\n",
    "        positive_examples = beta * np.mean(positive_examples, axis=0)\n",
    "        near_positives_examples = gamma * np.mean(near_positives_examples, axis=0)\n",
    "        #Calcolo il modello\n",
    "        model.append(((positive_examples - near_positives_examples), label))\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Training e test del modello rocchio con near positives"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR, EXPECTED sci.crypt GOT comp.sys.mac.hardware WITH SIM:  [0.96010116]\n",
      "ERROR, EXPECTED sci.crypt GOT comp.windows.x WITH SIM:  [0.97192239]\n",
      "ERROR, EXPECTED sci.med GOT talk.religion.misc WITH SIM:  [0.94983564]\n",
      "ERROR, EXPECTED misc.forsale GOT comp.windows.x WITH SIM:  [0.91604151]\n",
      "ERROR, EXPECTED misc.forsale GOT talk.politics.guns WITH SIM:  [0.97126263]\n",
      "ERROR, EXPECTED comp.sys.ibm.pc.hardware GOT comp.windows.x WITH SIM:  [0.91835666]\n",
      "ERROR, EXPECTED comp.sys.ibm.pc.hardware GOT comp.graphics WITH SIM:  [0.97850905]\n",
      "ERROR, EXPECTED comp.windows.x GOT sci.crypt WITH SIM:  [0.98127539]\n",
      "ERROR, EXPECTED comp.windows.x GOT comp.os.ms-windows.misc WITH SIM:  [0.9837652]\n",
      "ERROR, EXPECTED talk.religion.misc GOT sci.crypt WITH SIM:  [0.97990536]\n",
      "ERROR, EXPECTED comp.os.ms-windows.misc GOT comp.windows.x WITH SIM:  [0.93814874]\n",
      "ERROR, EXPECTED comp.os.ms-windows.misc GOT sci.crypt WITH SIM:  [0.97969467]\n",
      "ERROR, EXPECTED rec.sport.baseball GOT sci.med WITH SIM:  [0.97165375]\n",
      "ERROR, EXPECTED rec.sport.baseball GOT comp.windows.x WITH SIM:  [0.92416744]\n",
      "ERROR, EXPECTED comp.sys.mac.hardware GOT comp.sys.ibm.pc.hardware WITH SIM:  [0.96830975]\n",
      "ERROR, EXPECTED comp.sys.mac.hardware GOT comp.sys.ibm.pc.hardware WITH SIM:  [0.9608914]\n",
      "ERROR, EXPECTED rec.sport.hockey GOT rec.sport.baseball WITH SIM:  [0.90095107]\n",
      "ERROR, EXPECTED rec.sport.hockey GOT soc.religion.christian WITH SIM:  [0.97187181]\n",
      "ERROR, EXPECTED sci.electronics GOT comp.windows.x WITH SIM:  [0.95306575]\n",
      "ERROR, EXPECTED talk.politics.guns GOT talk.politics.mideast WITH SIM:  [0.9703178]\n",
      "ERROR, EXPECTED soc.religion.christian GOT talk.politics.misc WITH SIM:  [0.97473513]\n",
      "Accuracy: 46.15384615384615 % N_tests: 39 Hits: 18\n"
     ]
    }
   ],
   "source": [
    "#Alleno il modello\n",
    "model = train_rocchio_with_near_positives(x_train_data, y_train_data, 16, 4)\n",
    "hit = 0\n",
    "#Per ogni modello del test set verifico le predizioni\n",
    "for i, elem in enumerate(x_test_data):\n",
    "    predicted_value, sim = predict(elem, model)\n",
    "    if (predicted_value == y_test_data[i]):\n",
    "        hit += 1\n",
    "    else:\n",
    "        print(\"ERROR, EXPECTED\", y_test_data[i], \"GOT\", predicted_value, \"WITH SIM: \", sim)\n",
    "#Calcolo accuratezza\n",
    "if(hit==0):\n",
    "    prec=0\n",
    "else:\n",
    "    perc=(hit / len(x_test_data))*100\n",
    "print(\"Accuracy:\", perc, \"%\", \"N_tests:\",len(x_test_data),\"Hits:\",hit)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
