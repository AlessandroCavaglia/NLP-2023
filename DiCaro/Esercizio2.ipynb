{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tag import pos_tag\n",
    "from nltk.corpus import wordnet\n",
    "import statistics\n",
    "import pandas as pd\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "file_path = 'TLN-definitions-23.tsv'\n",
    "RELEVANT_WORD_SIZE_FOR_GENUS = 5\n",
    "MIN_SYNSET_HEIGHT = 2\n",
    "MEANING_CANDIDATES_SIZE = 5\n",
    "DEVIATION = 4 #Used for refine dataset\n",
    "\n",
    "meaningCandidates = []\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "def average_length(list):\n",
    "    lengths = [len(sublist) for sublist in list]\n",
    "    avg_length = statistics.mean(lengths)\n",
    "    return avg_length\n",
    "\n",
    "\n",
    "def refine_dataset(dataset, k):\n",
    "    for key in dataset:\n",
    "        avg = int(average_length(dataset[key]))\n",
    "        dataset[key] = [elem for elem in dataset[key] if abs(len(elem) - avg) <= k]\n",
    "        avg = int(average_length(dataset[key]))\n",
    "\n",
    "\n",
    "def parse_tsv_file(file_path):\n",
    "    df = pd.read_csv(file_path, sep='\\t')\n",
    "    return df\n",
    "\n",
    "\n",
    "def intersection(lst1, lst2):\n",
    "    lst3 = [value for value in lst1 if value in lst2]\n",
    "    return lst3\n",
    "\n",
    "#Lexical Overlap\n",
    "def calc_similarity(definition, lists):\n",
    "    result = 0\n",
    "    for list1 in lists:\n",
    "        #Divido per la media della lunghezza dei due e non per il minimo per evitare di avere un bias sui synset con descrizioni corte rispetto a synset con descrizioni piu lunghe\n",
    "        result += len(intersection(list1, definition)) / ((len(list1) + len(definition)) / 2)\n",
    "    return result / (len(lists))\n",
    "\n",
    "\n",
    "def lemmatized_tokens(text):\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    lemmas = []\n",
    "    for token, tag in pos_tag(tokens):\n",
    "        if token.isalpha() and token not in stop_words:\n",
    "            if tag.startswith('VB'):\n",
    "                lemmas.append(lemmatizer.lemmatize(token, pos='v'))\n",
    "            else:\n",
    "                lemmas.append(lemmatizer.lemmatize(token))\n",
    "    return lemmas\n",
    "\n",
    "#Seleziono la lista di Genus come termine piÃ¹ occorente all'interno delle descrizioni\n",
    "def getWordsInOrder(sentences):\n",
    "    print(\"ELABORATING WORDS FROM DATASET ON \", len(sentences), \" SENTENCES\")\n",
    "    words_dict = {}\n",
    "    for sentence in sentences:\n",
    "        for word in sentence:\n",
    "            if (word in words_dict):\n",
    "                words_dict[word] += 1\n",
    "            else:\n",
    "                words_dict[word] = 1\n",
    "    my_list = list(words_dict.items())\n",
    "    sorted_list = sorted(my_list, key=lambda x: x[1], reverse=True)\n",
    "    print(\"ELABORATED WORDS, SHOWING FIRST\", RELEVANT_WORD_SIZE_FOR_GENUS, \" RELEVANT WORDS FIND ON DESCRIPTIONS\")\n",
    "    #Select only TOP RELEVANT_WORD_SIZE_FOR_GENUS\n",
    "    for item in sorted_list[0:RELEVANT_WORD_SIZE_FOR_GENUS]:\n",
    "        print(item)\n",
    "    return sorted_list\n",
    "\n",
    "\n",
    "def getSynsetsInOrderFromWordNet(words):\n",
    "    print(\"ELABORATING SYNSET SEARCH ON \", len(words), \" WORDS\")\n",
    "    synsetWithHeight = []\n",
    "    for word in words:\n",
    "        synsets = wordnet.synsets(word[0])\n",
    "        for synset in synsets:\n",
    "            if synset.max_depth() > MIN_SYNSET_HEIGHT:\n",
    "                synsetWithHeight.append((synset.name(), synset.max_depth(), synset))\n",
    "    sortedSynsetWithHeight = sorted(synsetWithHeight, key=lambda x: x[1])\n",
    "    print(\"FOUND A TOTAL OF \", len(sortedSynsetWithHeight), \" SYNSETS \")\n",
    "    # for item in sortedSynsetWithHeight:\n",
    "    #    print(item)\n",
    "    return sortedSynsetWithHeight\n",
    "\n",
    "\n",
    "def calcSimilarityForSynset(synset, sentences):\n",
    "    if not any(synset.name() == item[0] for item in meaningCandidates):\n",
    "        similarity = calc_similarity(lemmatized_tokens(synset.definition()), sentences)\n",
    "        meaningCandidates.append((synset.name(), synset.definition(), similarity))\n",
    "\n",
    "    for hyponim in synset.hyponyms():\n",
    "        if not any(hyponim.name() == item[0] for item in meaningCandidates):\n",
    "            calcSimilarityForSynset(hyponim, sentences)\n",
    "\n",
    "\n",
    "def getMeaningCandidatesFromSynsets(synsets, sentences):\n",
    "    print(\"ELABORATING MEANING ON \", len(synsets), \" WITH A TOTAL OF \", len(sentences), \" DEFINITIONS\")\n",
    "    for synset in synsets:\n",
    "        calcSimilarityForSynset(synset[2], sentences)\n",
    "    sortedmeaningCandidates = sorted(meaningCandidates, key=lambda x: x[1], reverse=True)\n",
    "    print(\"ELABORATED MEANING, SHOWING FIRST \", MEANING_CANDIDATES_SIZE, \" RESULTS WITH SCORES: \")\n",
    "    for item in sortedmeaningCandidates[0:MEANING_CANDIDATES_SIZE]:\n",
    "        print(item)\n",
    "    return sortedmeaningCandidates[0:MEANING_CANDIDATES_SIZE]\n",
    "\n",
    "def clear_candidate():\n",
    "    while (len(meaningCandidates) > 0):\n",
    "        meaningCandidates.pop()\n",
    "\n",
    "def elaborate_dataset(dataframe):\n",
    "    dataset = {\n",
    "        'door': [],\n",
    "        'ladybug': [],\n",
    "        'pain': [],\n",
    "        'blurriness': []\n",
    "    }\n",
    "    dataframe = dataframe.iloc[:, 1:]  # Rimuovi la prima colona\n",
    "    for index, row in dataframe.iterrows():\n",
    "        for column in dataframe.columns:\n",
    "            dataset[column].extend([lemmatized_tokens(row[column])])\n",
    "    print(\"Refining dataset removing sentences that are at least \", DEVIATION, \" apart from avarage lenght\")\n",
    "    refine_dataset(dataset, DEVIATION)\n",
    "    return dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Refining dataset removing sentences that are at least  4  apart from avarage lenght\n"
     ]
    }
   ],
   "source": [
    "df = parse_tsv_file(file_path)\n",
    "dataset = elaborate_dataset(df)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Elaborate Door"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ELABORATING DOOR\n",
      "ELABORATING WORDS FROM DATASET ON  24  SENTENCES\n",
      "ELABORATED WORDS, SHOWING FIRST 5  RELEVANT WORDS FIND ON DESCRIPTIONS\n",
      "('room', 11)\n",
      "('access', 10)\n",
      "('object', 10)\n",
      "('open', 7)\n",
      "('allow', 7)\n",
      "ELABORATING SYNSET SEARCH ON  5  WORDS\n",
      "FOUND A TOTAL OF  27  SYNSETS \n",
      "ELABORATING MEANING ON  27  WITH A TOTAL OF  24  DEFINITIONS\n",
      "ELABORATED MEANING, SHOWING FIRST  5  RESULTS WITH SCORES: \n",
      "('doorway.n.01', 0.18539547791676272, 'the entrance (the space in a wall) through which you enter or leave a room or building; the space that a door can close')\n",
      "('dining_room.n.01', 0.1396843896843897, 'a room used for dining')\n",
      "('anteroom.n.01', 0.13119924057424057, 'a large entrance or reception room or area')\n",
      "('exterior_door.n.01', 0.1300189393939394, 'a doorway that allows entrance to or exit from a building')\n",
      "('bedroom.n.01', 0.12582163207163208, 'a room used primarily for sleeping')\n"
     ]
    }
   ],
   "source": [
    "print(\"ELABORATING DOOR\")\n",
    "\n",
    "doorWords = getWordsInOrder(dataset['door'])\n",
    "doorParentSynsetCandidates = getSynsetsInOrderFromWordNet(doorWords[0:RELEVANT_WORD_SIZE_FOR_GENUS])\n",
    "doorMeaningCandidates = getMeaningCandidatesFromSynsets(doorParentSynsetCandidates, dataset['door'])\n",
    "clear_candidate()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Elaborate Ladybug"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ELABORATING LADYBUG\n",
      "ELABORATING WORDS FROM DATASET ON  26  SENTENCES\n",
      "ELABORATED WORDS, SHOWING FIRST 5  RELEVANT WORDS FIND ON DESCRIPTIONS\n",
      "('insect', 24)\n",
      "('red', 22)\n",
      "('small', 17)\n",
      "('black', 17)\n",
      "('dot', 16)\n",
      "ELABORATING SYNSET SEARCH ON  5  WORDS\n",
      "FOUND A TOTAL OF  20  SYNSETS \n",
      "ELABORATING MEANING ON  20  WITH A TOTAL OF  26  DEFINITIONS\n",
      "ELABORATED MEANING, SHOWING FIRST  5  RESULTS WITH SCORES: \n",
      "('buffalo_carpet_beetle.n.01', 0.3422185594696907, 'a small black and red and white carpet beetle')\n",
      "('aphid.n.01', 0.33959822229052994, 'any of various small plant-sucking insects')\n",
      "('two-spotted_ladybug.n.01', 0.290547059777829, 'red ladybug with a black spot on each wing')\n",
      "('leaf_bug.n.01', 0.2776053006822238, 'small bright-colored insect that feeds on plant juices')\n",
      "('chinch_bug.n.01', 0.2776053006822238, 'small black-and-white insect that feeds on cereal grasses')\n"
     ]
    }
   ],
   "source": [
    "print(\"ELABORATING LADYBUG\")\n",
    "\n",
    "ladyBugWords = getWordsInOrder(dataset['ladybug'])\n",
    "ladyBugParentSynsetCandidates = getSynsetsInOrderFromWordNet(ladyBugWords[0:RELEVANT_WORD_SIZE_FOR_GENUS])\n",
    "ladyBugMeaningCandidates = getMeaningCandidatesFromSynsets(ladyBugParentSynsetCandidates, dataset['ladybug'])\n",
    "clear_candidate()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Elaborate Pain"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ELABORATING PAIN\n",
      "ELABORATING WORDS FROM DATASET ON  26  SENTENCES\n",
      "ELABORATED WORDS, SHOWING FIRST 5  RELEVANT WORDS FIND ON DESCRIPTIONS\n",
      "('physical', 12)\n",
      "('feeling', 11)\n",
      "('emotional', 9)\n",
      "('sensation', 9)\n",
      "('cause', 6)\n",
      "ELABORATING SYNSET SEARCH ON  5  WORDS\n",
      "FOUND A TOTAL OF  17  SYNSETS \n",
      "ELABORATING MEANING ON  17  WITH A TOTAL OF  26  DEFINITIONS\n",
      "ELABORATED MEANING, SHOWING FIRST  5  RESULTS WITH SCORES: \n",
      "('suffering.n.04', 0.22616977040053962, 'feelings of mental or physical pain')\n",
      "('feeling.n.04', 0.2213675213675214, 'a physical sensation that you experience')\n",
      "('agony.n.01', 0.181472480510942, 'intense feelings of suffering; acute mental or physical pain')\n",
      "('wildness.n.01', 0.1781985108908186, 'a feeling of extreme emotional intensity')\n",
      "('sensitivity.n.03', 0.1591963591963592, 'sensitivity to emotional feelings (of self and others)')\n"
     ]
    }
   ],
   "source": [
    "print(\"ELABORATING PAIN\")\n",
    "\n",
    "painWords = getWordsInOrder(dataset['pain'])\n",
    "painParentSynsetCandidates = getSynsetsInOrderFromWordNet(painWords[0:RELEVANT_WORD_SIZE_FOR_GENUS])\n",
    "painMeaningCandidates = getMeaningCandidatesFromSynsets(painParentSynsetCandidates, dataset['pain'])\n",
    "clear_candidate()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Elaborate Blurriness"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ELABORATING BLURRINESS\n",
      "ELABORATING WORDS FROM DATASET ON  22  SENTENCES\n",
      "ELABORATED WORDS, SHOWING FIRST 5  RELEVANT WORDS FIND ON DESCRIPTIONS\n",
      "('see', 7)\n",
      "('image', 6)\n",
      "('visual', 5)\n",
      "('border', 4)\n",
      "('eye', 4)\n",
      "ELABORATING SYNSET SEARCH ON  5  WORDS\n",
      "FOUND A TOTAL OF  34  SYNSETS \n",
      "ELABORATING MEANING ON  34  WITH A TOTAL OF  22  DEFINITIONS\n",
      "ELABORATED MEANING, SHOWING FIRST  5  RESULTS WITH SCORES: \n",
      "('memory_picture.n.01', 0.10887546796637704, 'a memory image that is similar to a visual perception')\n",
      "('visual_image.n.01', 0.10129971039061947, 'a mental image that is similar to a visual perception')\n",
      "('mental_picture.n.01', 0.07097599370326645, 'a clear and telling mental image')\n",
      "('eye.n.03', 0.06633644133644134, 'attention to what is seen')\n",
      "('naked_eye.n.01', 0.060905235000304696, 'the eye unaided by any optical instrument that alters the power of vision or alters the apparent size or distance of objects')\n"
     ]
    }
   ],
   "source": [
    "print(\"ELABORATING BLURRINESS\")\n",
    "\n",
    "blurrinessBugWords = getWordsInOrder(dataset['blurriness'])\n",
    "blurrinessParentSynsetCandidates = getSynsetsInOrderFromWordNet(blurrinessBugWords[0:RELEVANT_WORD_SIZE_FOR_GENUS])\n",
    "blurrinessMeaningCandidates = getMeaningCandidatesFromSynsets(blurrinessParentSynsetCandidates,\n",
    "                                                              dataset['blurriness'])"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
